{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "\n",
    "Topics Yet To Cover\n",
    "* Scalar Projection\n",
    "* EigenVectors/Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Independence, Spans, Basis Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>In 2-D</strong> Two vectors are Linearly Independent if one can't be represented as a scaled version of the other. \n",
    "\n",
    "In 2-D this is easy to see. Two vectors are linearly dependent if they lie on top of one another, since they're simply scaled versions of one another.\n",
    "\n",
    "<strong>In general,</strong> a set of vectors is linearly independent if none of them can be represented as a linear combination of the others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A span of a vector or vectors is the set of all their linear combinations. \n",
    "\n",
    "The two vectors that lie on top of one another can only <strong>span</strong> the set of vectors that also lie on that line. \n",
    "\n",
    "However, if the two vectors don't lie on top of one another, i.e. they're independent, then those two vectors span the entire 2-D plane. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis vectors are the m linearly independent set of vectors that can span the entire m-dimensional space they occupy.\n",
    "\n",
    "For example, any two 2d vectors that don't lie on top of one another (i.e. linearly independent) can span the entire 2-dimensional plane. \n",
    "\n",
    "Typically, we use the standard basis vectors, $\\hat{i}$, $\\hat{j}$, $\\hat{k}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometrically, matrices can be interpreted in two ways <font color=red>(that i know of so far)</font>.\n",
    "1. [Transformations](https://www.youtube.com/watch?v=kYB8IZa5AuE)\n",
    "2. [Change of basis](https://www.youtube.com/watch?v=P2LTAUO1TdA&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=14&t=0s)\n",
    "3. Sets of Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "They can be seen as transformations, that is:\n",
    "* rotations\n",
    "* scaling (negative scaling is equivalent to flipping)\n",
    "* shearing\n",
    "\n",
    "The reason these transformations are called 'linear' is because of two reasons:\n",
    "1. All vectors that were a line before, remain a line afterwards. That is, the transformation leaves gridlines parallel and evenly spaced. \n",
    "2. And the origin remains fixed.  \n",
    "\n",
    "An easy way to interpret the values of a matrix is to see its columns as the coordinates at which the basis vectors land after the transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, it's easy to see how all vectors in the space would be transformed in the same manner:\n",
    "\n",
    "$$\n",
    "\\newcommand{\\ihat}{\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "}\n",
    "\\\\~\\\\\n",
    "\\newcommand{\\jhat}{\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "}\n",
    "\\\\~\\\\\n",
    "\\hat{i} = \\ihat\n",
    "\\\\~\\\\\n",
    "\\hat{j} = \\jhat\n",
    "\\\\~\\\\\n",
    "\\vec{v} = \\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "\\\\~\\\\\n",
    "\\vec{v} = x\\hat{i} + y\\hat{j}\n",
    "\\\\~\\\\\n",
    "\\vec{v} = x\\ihat + y\\jhat\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now define a matrix M which will linearly tranform our space.\n",
    "$$\n",
    "\\newcommand{\\mmatrix}{\\begin{pmatrix}\n",
    "a &b \\\\\n",
    "c &d \\\\\n",
    "\\end{pmatrix}}\n",
    "\\\\~\\\\\n",
    "M = \\mmatrix\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply the matrix $M$ to our basis vectors:\n",
    "\n",
    "$$\n",
    "\\newcommand{\\mfirstcol}{\\begin{bmatrix}\n",
    "a \\\\\n",
    "c\n",
    "\\end{bmatrix}}\n",
    "\\newcommand{\\msecondcol}{\\begin{bmatrix}\n",
    "b \\\\\n",
    "d\n",
    "\\end{bmatrix}}\n",
    "M\\hat{i} = M\\ihat = \\mfirstcol\n",
    "\\\\~\\\\\n",
    "M\\hat{j} = M\\jhat = \\msecondcol\n",
    "$$\n",
    "\n",
    "That is, our standard basis vectors are transformed so they're now at the column vectors that define $M$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every vector in 2-D space can be rewritten in terms of our basis vectors:\n",
    "$$\n",
    "\\vec{v} = x\\ihat + y\\jhat\n",
    "$$\n",
    "\n",
    "When we take the vector $\\vec{v}$ and left-multiply it by a matrix $M$, what we're actually doing is:\n",
    "\n",
    "$$\n",
    "M\\vec{v} = M(x\\hat{i} + y\\hat{j})\n",
    "\\\\~\\\\\n",
    "M\\vec{v} = x(M\\hat{i}) + y(M\\hat{j})\n",
    "\\\\~\\\\\n",
    "M\\vec{v} = x\\mfirstcol + y\\msecondcol\n",
    "$$\n",
    "\n",
    "$\\vec{v}$ remains a linear combination of basis vectors, except those standard basis vectors have now undergone a linear transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change of Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They can be seen as a change of basis if we simply take the transpose of M above.\n",
    "\n",
    "This is because then the vector $\\vec{v}$ is **no longer** used to linearly combine the vectors as a transforamtion, but instead, the resulting vector is composed of the dot-product of $\\vec{v}$ with each the new axes.\n",
    "\n",
    "That is, the resulting vector is composed of $\\vec{v}$'s scalar projection onto each of the axes:\n",
    "\n",
    "$$\n",
    "M^{T}\\vec{v} = \\begin{bmatrix}\n",
    "\\vec{v}^{T}\\mfirstcol \\\\\n",
    "\\vec{v}^{T}\\msecondcol\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Since it's a scalar projection, the resulting scalar values define $\\vec{v}$ in a coordinate system with $M$'s rows as its basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-notes",
   "language": "python",
   "name": "ml-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
